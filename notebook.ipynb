{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dicoding_ml.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaUCvrFVVxf"
      },
      "source": [
        "<p> <strong>Nama:</strong> Naufal Prima Yoriko</p>\n",
        "<p> <strong>Email:</strong> primayoriko@gmail.com </p>\n",
        "<p> <strong>Username:</strong> primayoriko </p>\n",
        "<p> <strong>Dicoding Profile:</strong> https://www.dicoding.com/users/primayoriko </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Gu5tHLWn4b"
      },
      "source": [
        "# **Submission PaperRockScissors**\n",
        "\n",
        "Sebelum menuju ke langkah pengerjaan, ini terdapat beberapa referensi yang saya pakai\n",
        "\n",
        "1.   Neural Network Activation Function in Keras\n",
        "     *   https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
        "     *   https://keras.io/api/layers/activations/\n",
        "\n",
        "2.   Loss Function in Keras\n",
        "     *   https://neptune.ai/blog/keras-loss-functions\n",
        "     *   https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "     *   https://keras.io/api/losses/\n",
        "     *   https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "\n",
        "3.   Callback in Keras\n",
        "     * https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/\n",
        "\n",
        "4.   Optimization in Keras\n",
        "     * https://keras.io/api/optimizers/ \n",
        "\n",
        "5.   Performance comparison\n",
        "     * https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/\n",
        "     * https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\n",
        "     * https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/70253\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvJ4okkL4BVz"
      },
      "source": [
        "Berikut ini adalah tahap-tahap pengerjaan yang saya lakukan dalam memeroleh hasil dari Image Processing menggunakan CNN (*Convolutional Neural Network*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynODMQpPW8tu"
      },
      "source": [
        "**Pertama**, mendownload file dari web dicoding dengan menggunakan utilitas `wget`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7gmOZAWtrTD",
        "outputId": "3e2a2fea-0337-4a2b-e3ab-8b3da2e85909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-31 19:05:57--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/zip]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M  6.24MB/s    in 48s     \n",
            "\n",
            "2020-10-31 19:06:46 (6.37 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aicDtAVnXGbI"
      },
      "source": [
        "**Kedua**, melakukan ekstraksi dari file yang didownload dengan menggunakan `zipfile`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on8Gsccut4hn"
      },
      "source": [
        "import zipfile,os\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnUXREs-XTli"
      },
      "source": [
        "**Ketiga**, dengan menggunakan library tambahan yaitu `split-folder`, saya melakukan splitting dari file-file gambar menjadi training (`train`) dan validation (`val`) data. \n",
        "\n",
        "**Note:** referensi split saya dapat dari forum dicoding, saya rasa karena dari forum, bukan website luar, tidak apa-apa untuk diikuti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HbKvdJ8xg4g",
        "outputId": "bb7a7f6f-8b11-42d9-93c3-938e5955de51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', output='/tmp/rockpaperscissors/splitted', seed=1337, ratio=(.6, .4))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4b/7b282b0f9319189d71e803220748929b37d019b67b1782d14c59cb1bd940/split_folders-0.4.2-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 2188 files [00:00, 2867.24 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVQBG8DaYGVg"
      },
      "source": [
        "**Keempat**, saya mencatat direktori dari tiap tipe data, `train` dan `val` data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYcmKDZXuBEv",
        "outputId": "4922a499-7e0a-4d48-dbfb-a77d504c4012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_dir = '/tmp/rockpaperscissors/splitted'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "print(train_dir)\n",
        "print(validation_dir)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/rockpaperscissors/splitted/train\n",
            "/tmp/rockpaperscissors/splitted/val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tHb1z0kYSAb"
      },
      "source": [
        "**Kelima**, mencatat direktori dari tiap-tiap kategori gambar dan juga mencatat total file image di tiap segmennya, untuk berjaga semisal akan dibutuhkan kedepannya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWfP7CkUuJiv",
        "outputId": "b5a93c5e-c011-4fd8-b69c-b5bf8c457b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_paper_dir = os.path.join(train_dir, 'paper')\n",
        "train_scissors_dir = os.path.join(train_dir, 'scissors')\n",
        "train_rock_dir = os.path.join(train_dir, 'rock')\n",
        "\n",
        "validation_paper_dir = os.path.join(validation_dir, 'paper')\n",
        "validation_scissors_dir = os.path.join(validation_dir, 'scissors')\n",
        "validation_rock_dir = os.path.join(validation_dir, 'rock')\n",
        "\n",
        "train_paper = len(os.listdir(train_paper_dir))\n",
        "train_scissors = len(os.listdir(train_scissors_dir))\n",
        "train_rock = len(os.listdir(train_rock_dir))\n",
        "\n",
        "validation_paper = len(os.listdir(validation_paper_dir))\n",
        "validation_scissors = len(os.listdir(validation_scissors_dir))\n",
        "validation_rock = len(os.listdir(validation_rock_dir))\n",
        "\n",
        "total_train = train_paper + train_scissors + train_rock\n",
        "total_validation = validation_paper + validation_scissors + validation_rock\n",
        "\n",
        "print(total_train)\n",
        "print(total_validation)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1312\n",
            "876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1DVvWsgYveG"
      },
      "source": [
        "**Keenam**, pembuatan generator image dari gambar-gambar yang tersedia, dengan menggunakan `ImageDataGenerator` dari Keras. Fungsi dari image data generator ini adalah untuk membantu mengklasifikasikan suatu gambar ke kategoti tertentu karena pada gambar mungkin ada faktor tertentu yang membedakan tampilan (diluar karena perbedaan objek), seperti jarak/ukuran, orientasi, gradasi warna, dll.\n",
        "\n",
        "Disini kode yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qJYcVJVztO1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    shear_range=0.2,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode = 'nearest'\n",
        "                  )\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    shear_range=0.2,\n",
        "                    # width_shift_range=0.2,\n",
        "                    # height_shift_range=0.2,\n",
        "                    # zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode = 'nearest'\n",
        "                  )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPPl7qqb9BH7"
      },
      "source": [
        "**Keenam**, Membuat pengaturan dimensi image, class, dan juga flow dari transfer data image dalam pembuatan model di tiap batchnya.\n",
        "\n",
        "Disini kode yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini. Namun, terdapat penyesuaian size tiap batch-nya sekaligus `class_mode` nya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfXlhNo3miH",
        "outputId": "c49998bd-2e3c-4959-83ce-c287c0704fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "# Diasumsikan akan dibuat dibuat 25 step tiap epoch\n",
        "steps_per_epoch = 25\n",
        "\n",
        "# Maka berikut ini jumlah file di tiap flow\n",
        "train_per_batch = ceil(total_train/steps_per_epoch)\n",
        "val_per_batch = ceil(total_validation/steps_per_epoch)\n",
        "print(train_per_batch)\n",
        "print(val_per_batch)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    target_size=(150, 150),\n",
        "                    batch_size=train_per_batch,\n",
        "                    class_mode='categorical'\n",
        "                  )\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                          validation_dir,\n",
        "                          target_size=(150, 150),\n",
        "                          batch_size=val_per_batch,\n",
        "                          class_mode='categorical'\n",
        "                        )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "36\n",
            "Found 1312 images belonging to 3 classes.\n",
            "Found 876 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjjqtJVEYy5J"
      },
      "source": [
        "**Ketujuh**, membuat struktur dari CNN. CNN yang dibuat disini, sesuai spesifikasi menggunakan model sequensial, yang susunannya dibebaskan (asal memiliki > 1 hidden layer).\n",
        "\n",
        "Disini kode/model yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini. Namun, ........"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIN4TTi4Ysn"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation= 'softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIxTkLrcY684"
      },
      "source": [
        "**Kedelapan**,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJk0tuG6IH_o"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8A30LlQIRln"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=6,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2YtukPyTuP1",
        "outputId": "cfcbb16a-f86f-4c8f-88a8-976bc35b4069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "# opt = Adam(amsgrad=True)\n",
        "opt = SGD(\n",
        "    lr=0.01, momentum=0.9, nesterov=False\n",
        ")\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "25/25 - 60s - loss: 1.0957 - accuracy: 0.3445 - val_loss: 1.0756 - val_accuracy: 0.4833\n",
            "Epoch 2/12\n",
            "25/25 - 60s - loss: 1.0693 - accuracy: 0.4268 - val_loss: 0.9876 - val_accuracy: 0.5167\n",
            "Epoch 3/12\n",
            "25/25 - 63s - loss: 0.9753 - accuracy: 0.5488 - val_loss: 0.7969 - val_accuracy: 0.7944\n",
            "Epoch 4/12\n",
            "25/25 - 60s - loss: 0.8593 - accuracy: 0.5960 - val_loss: 0.5855 - val_accuracy: 0.7556\n",
            "Epoch 5/12\n",
            "25/25 - 59s - loss: 0.6957 - accuracy: 0.7096 - val_loss: 0.4364 - val_accuracy: 0.9111\n",
            "Epoch 6/12\n",
            "25/25 - 59s - loss: 0.5474 - accuracy: 0.7843 - val_loss: 0.4002 - val_accuracy: 0.8778\n",
            "Epoch 7/12\n",
            "25/25 - 59s - loss: 0.4315 - accuracy: 0.8377 - val_loss: 0.2308 - val_accuracy: 0.9444\n",
            "Epoch 8/12\n",
            "25/25 - 59s - loss: 0.4448 - accuracy: 0.8247 - val_loss: 0.2580 - val_accuracy: 0.9500\n",
            "Epoch 9/12\n",
            "25/25 - 60s - loss: 0.3636 - accuracy: 0.8659 - val_loss: 0.2153 - val_accuracy: 0.9556\n",
            "Epoch 10/12\n",
            "25/25 - 60s - loss: 0.2979 - accuracy: 0.9055 - val_loss: 0.1096 - val_accuracy: 0.9667\n",
            "Epoch 11/12\n",
            "25/25 - 60s - loss: 0.3022 - accuracy: 0.8902 - val_loss: 0.1893 - val_accuracy: 0.9333\n",
            "Epoch 12/12\n",
            "25/25 - 59s - loss: 0.2611 - accuracy: 0.9024 - val_loss: 0.1860 - val_accuracy: 0.9278\n",
            "--- Finished in 752.9087994098663 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB4-8SjARdyi",
        "outputId": "517b24e2-9f1f-4fc0-a6cf-87a248947565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "# opt = Adam(amsgrad=True)\n",
        "opt = SGD(\n",
        "    lr=0.01, momentum=0.9, nesterov=True\n",
        ")\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "25/25 - 63s - loss: 1.0925 - accuracy: 0.4108 - val_loss: 1.0723 - val_accuracy: 0.4222\n",
            "Epoch 2/12\n",
            "25/25 - 60s - loss: 1.0577 - accuracy: 0.4436 - val_loss: 0.9289 - val_accuracy: 0.6111\n",
            "Epoch 3/12\n",
            "25/25 - 60s - loss: 0.9754 - accuracy: 0.5389 - val_loss: 0.7267 - val_accuracy: 0.8222\n",
            "Epoch 4/12\n",
            "25/25 - 60s - loss: 0.8009 - accuracy: 0.6730 - val_loss: 1.2443 - val_accuracy: 0.4056\n",
            "Epoch 5/12\n",
            "25/25 - 59s - loss: 1.1525 - accuracy: 0.4200 - val_loss: 0.9915 - val_accuracy: 0.6056\n",
            "Epoch 6/12\n",
            "25/25 - 59s - loss: 0.8816 - accuracy: 0.6166 - val_loss: 0.6166 - val_accuracy: 0.7389\n",
            "Epoch 7/12\n",
            "25/25 - 60s - loss: 0.6576 - accuracy: 0.7325 - val_loss: 0.3380 - val_accuracy: 0.9056\n",
            "Epoch 8/12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCgLsqRGiD90"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPWelqaLvbxR"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEd9hA2mv_-D"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTBKPuhliXN0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=True\n",
        "# )\n",
        "\n",
        "model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeKeLnPqM4Jp",
        "outputId": "54f67991-55ec-421e-ead5-ddc607488705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=True\n",
        "# )\n",
        "\n",
        "model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=7,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "25/25 - 60s - loss: 0.1945 - accuracy: 0.3788 - val_loss: 0.1761 - val_accuracy: 0.6778\n",
            "Epoch 2/7\n",
            "25/25 - 60s - loss: 0.1786 - accuracy: 0.4825 - val_loss: 0.1658 - val_accuracy: 0.5944\n",
            "Epoch 3/7\n",
            "25/25 - 59s - loss: 0.1618 - accuracy: 0.5846 - val_loss: 0.0926 - val_accuracy: 0.9611\n",
            "Epoch 4/7\n",
            "25/25 - 60s - loss: 0.1036 - accuracy: 0.7973 - val_loss: 0.0528 - val_accuracy: 0.9444\n",
            "Epoch 5/7\n",
            "25/25 - 63s - loss: 0.0695 - accuracy: 0.8880 - val_loss: 0.0425 - val_accuracy: 0.9500\n",
            "Epoch 6/7\n",
            "25/25 - 60s - loss: 0.0561 - accuracy: 0.9177 - val_loss: 0.0456 - val_accuracy: 0.9667\n",
            "Epoch 7/7\n",
            "25/25 - 59s - loss: 0.0376 - accuracy: 0.9428 - val_loss: 0.0172 - val_accuracy: 0.9833\n",
            "--- Finished in 441.4690737724304 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ewNS6vvUAV",
        "outputId": "ae907b0a-89fe-428e-e2f3-3ca609f1042a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=7,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "25/25 - 61s - loss: 1.1147 - accuracy: 0.3445 - val_loss: 1.0836 - val_accuracy: 0.3556\n",
            "Epoch 2/7\n",
            "25/25 - 60s - loss: 0.9432 - accuracy: 0.5366 - val_loss: 0.5360 - val_accuracy: 0.8389\n",
            "Epoch 3/7\n",
            "25/25 - 60s - loss: 0.5590 - accuracy: 0.7759 - val_loss: 0.3567 - val_accuracy: 0.8722\n",
            "Epoch 4/7\n",
            "25/25 - 59s - loss: 0.4956 - accuracy: 0.7904 - val_loss: 0.2802 - val_accuracy: 0.9278\n",
            "Epoch 5/7\n",
            "25/25 - 63s - loss: 0.3847 - accuracy: 0.8651 - val_loss: 0.1175 - val_accuracy: 0.9778\n",
            "Epoch 6/7\n",
            "25/25 - 60s - loss: 0.3941 - accuracy: 0.8552 - val_loss: 0.1961 - val_accuracy: 0.9500\n",
            "Epoch 7/7\n",
            "25/25 - 59s - loss: 0.2763 - accuracy: 0.9009 - val_loss: 0.1356 - val_accuracy: 0.9722\n",
            "--- Finished in 443.3176734447479 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqKadqZaFHU"
      },
      "source": [
        "Dari sini, didapati akurasi sebesar **99.44%** pada `val` data, sedangkan akurasi sebesar **98.02%** pada `train` data sendiri. Untuk waktu eksekusi, training dan validasi data memakan waktu selama **1411 s** ~ **24 min**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjwHrefXBbT1"
      },
      "source": [
        "**Kesembilan**, ini opsional, semisal anda ingin mencoba memasukkan untuk menguji suatu image tangan guna diklasifikasikan ke dalam salah satu kategori (paper, rock, scissors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JszJptL5JExy"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as mpimg\n",
        "# %matplotlib inline\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  # imgplot = plt.imshow(img)\n",
        "  # x = image.img_to_array(img)\n",
        "  # x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  print(classes)\n",
        "\n",
        "  # if classes==0:\n",
        "  #   print('clean')\n",
        "  # else:\n",
        "  #   print('messy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efHTda8irWsm"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications import VGG16\n",
        "\n",
        "\n",
        "prior = VGG16(\n",
        "    include_top=False, \n",
        "    weights='imagenet',\n",
        "    input_shape=(150, 150, 3)\n",
        ")\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(prior)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "# model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True)\n",
        "\n",
        "model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=7,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}