{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaUCvrFVVxf"
      },
      "source": [
        "<p> <strong>Nama:</strong> Naufal Prima Yoriko</p>\n",
        "<p> <strong>Email:</strong> primayoriko@gmail.com </p>\n",
        "<p> <strong>Username:</strong> primayoriko </p>\n",
        "<p> <strong>Dicoding Profile:</strong> https://www.dicoding.com/users/primayoriko </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Gu5tHLWn4b"
      },
      "source": [
        "# **Submission PaperRockScissors**\n",
        "\n",
        "Sebelum menuju ke langkah pengerjaan, ini terdapat beberapa referensi yang saya pakai\n",
        "\n",
        "1.   Neural Network Activation Function in Keras\n",
        "     *   https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
        "     *   https://keras.io/api/layers/activations/\n",
        "\n",
        "2.   Loss Function in Keras\n",
        "     *   https://neptune.ai/blog/keras-loss-functions\n",
        "     *   https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "     *   https://keras.io/api/losses/\n",
        "     *   https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "\n",
        "3.   Callback in Keras\n",
        "     * https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/\n",
        "\n",
        "4.   Optimization in Keras\n",
        "     * https://keras.io/api/optimizers/ \n",
        "\n",
        "5.   Performance comparison\n",
        "     * https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/\n",
        "     * https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\n",
        "     * https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/70253\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvJ4okkL4BVz"
      },
      "source": [
        "Berikut ini adalah tahap-tahap pengerjaan yang saya lakukan dalam memeroleh hasil dari Image Processing menggunakan CNN (*Convolutional Neural Network*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynODMQpPW8tu"
      },
      "source": [
        "**Pertama**, mendownload file dari web dicoding dengan menggunakan utilitas `wget`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7gmOZAWtrTD",
        "outputId": "7b637e30-90a9-40ca-a04f-bc745704308f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-02 02:48:24--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/zip]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M  11.9MB/s    in 30s     \n",
            "\n",
            "2020-11-02 02:48:54 (10.4 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aicDtAVnXGbI"
      },
      "source": [
        "**Kedua**, melakukan ekstraksi dari file yang didownload dengan menggunakan `zipfile`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on8Gsccut4hn"
      },
      "source": [
        "import zipfile,os\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnUXREs-XTli"
      },
      "source": [
        "**Ketiga**, dengan menggunakan library tambahan yaitu `split-folder`, saya melakukan splitting dari file-file gambar menjadi training (`train`) dan validation (`val`) data. \n",
        "\n",
        "**Note:** referensi split saya dapat dari forum dicoding, saya rasa karena dari forum, bukan website luar, tidak apa-apa untuk diikuti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HbKvdJ8xg4g",
        "outputId": "ac3b2f3f-47b2-4baa-adb9-e68bbb5a9e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', output='/tmp/rockpaperscissors/splitted', seed=1337, ratio=(.6, .4))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.6/dist-packages (0.4.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 2188 files [00:01, 1679.69 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVQBG8DaYGVg"
      },
      "source": [
        "**Keempat**, saya mencatat direktori dari tiap tipe data, `train` dan `val` data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYcmKDZXuBEv",
        "outputId": "3ab1d649-9138-4cf2-861a-42ed27eb5f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_dir = '/tmp/rockpaperscissors/splitted'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "print(train_dir)\n",
        "print(validation_dir)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/rockpaperscissors/splitted/train\n",
            "/tmp/rockpaperscissors/splitted/val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tHb1z0kYSAb"
      },
      "source": [
        "**Kelima**, mencatat direktori dari tiap-tiap kategori gambar dan juga mencatat total file image di tiap segmennya, untuk berjaga semisal akan dibutuhkan kedepannya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWfP7CkUuJiv",
        "outputId": "6f608740-87dd-4110-cc53-097d7bcb446f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_paper_dir = os.path.join(train_dir, 'paper')\n",
        "train_scissors_dir = os.path.join(train_dir, 'scissors')\n",
        "train_rock_dir = os.path.join(train_dir, 'rock')\n",
        "\n",
        "validation_paper_dir = os.path.join(validation_dir, 'paper')\n",
        "validation_scissors_dir = os.path.join(validation_dir, 'scissors')\n",
        "validation_rock_dir = os.path.join(validation_dir, 'rock')\n",
        "\n",
        "train_paper = len(os.listdir(train_paper_dir))\n",
        "train_scissors = len(os.listdir(train_scissors_dir))\n",
        "train_rock = len(os.listdir(train_rock_dir))\n",
        "\n",
        "validation_paper = len(os.listdir(validation_paper_dir))\n",
        "validation_scissors = len(os.listdir(validation_scissors_dir))\n",
        "validation_rock = len(os.listdir(validation_rock_dir))\n",
        "\n",
        "total_train = train_paper + train_scissors + train_rock\n",
        "total_validation = validation_paper + validation_scissors + validation_rock\n",
        "\n",
        "print(total_train)\n",
        "print(total_validation)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1312\n",
            "876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1DVvWsgYveG"
      },
      "source": [
        "**Keenam**, pembuatan generator image dari gambar-gambar yang tersedia, dengan menggunakan `ImageDataGenerator` dari Keras. Fungsi dari image data generator ini adalah untuk membantu mengklasifikasikan suatu gambar ke kategoti tertentu karena pada gambar mungkin ada faktor tertentu yang membedakan tampilan (diluar karena perbedaan objek), seperti jarak/ukuran, orientasi, gradasi warna, dll.\n",
        "\n",
        "Disini kode yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini, namun memiliki beberapa tambahan yaitu\n",
        "\n",
        "1.   Shifting lebar dari gambar dengan range 0.2\n",
        "2.   Shifting tinggi dari gambar dengan range 0.2\n",
        "3.   Shifting zoom/perbesaran gambar dengan range 0.2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qJYcVJVztO1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    shear_range=0.2,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode = 'nearest'\n",
        "                  )\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    shear_range=0.2,\n",
        "                    # width_shift_range=0.2,\n",
        "                    # height_shift_range=0.2,\n",
        "                    # zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode = 'nearest'\n",
        "                  )"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPPl7qqb9BH7"
      },
      "source": [
        "**Keenam**, Membuat pengaturan dimensi image, class, dan juga flow dari transfer data image dalam pembuatan model di tiap batchnya.\n",
        "\n",
        "Disini kode yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini. Namun, terdapat penyesuaian size tiap batch-nya sekaligus `class_mode` nya.\n",
        "\n",
        "Flow diatur agar pada satu epoch seluruh data pada dataset termuat untuk fitting model, atau \n",
        "\n",
        "\n",
        "```\n",
        "   steps_per_epoch * batch_per_steps ~ total data\n",
        "```\n",
        "\n",
        "Selain itu gambar yang digenerate disetting agar memiliki dimensi `150x150`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfXlhNo3miH",
        "outputId": "9b8d147f-6be8-4274-b862-563e5d0b8a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "# Diasumsikan akan dibuat dibuat 25 step tiap epoch\n",
        "steps_per_epoch = 25\n",
        "\n",
        "# Maka berikut ini jumlah file di tiap flow\n",
        "train_per_batch = ceil(total_train/steps_per_epoch)\n",
        "val_per_batch = ceil(total_validation/steps_per_epoch)\n",
        "print(train_per_batch)\n",
        "print(val_per_batch)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    target_size=(150, 150),\n",
        "                    batch_size=train_per_batch,\n",
        "                    class_mode='categorical'\n",
        "                  )\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                          validation_dir,\n",
        "                          target_size=(150, 150),\n",
        "                          batch_size=val_per_batch,\n",
        "                          class_mode='categorical'\n",
        "                        )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "36\n",
            "Found 1312 images belonging to 3 classes.\n",
            "Found 876 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjjqtJVEYy5J"
      },
      "source": [
        "**Ketujuh**, membuat struktur dari CNN. CNN yang dibuat disini, sesuai spesifikasi menggunakan model sequensial, yang susunannya dibebaskan (asal memiliki > 1 hidden layer).\n",
        "\n",
        "Disini kode/model yang digunakan memiliki struktur dasar dari `Latihan Membuat Model Klasifikasi Gambar` di kelas ini. Namun, metode penulisan dibuat lebih modular dan juga secara umum dapat dijelaskan bahwa struktur CNN yang sequensial memiliki 1 layer input, 9 layer hidden, dan 1 layer output.\n",
        "\n",
        "Aksi yang dilakukan antara lain dapat diringkas sebagai berikut\n",
        "\n",
        "1.   Input (beririsan dengan convolution layer) meminta input sebesar `150x150` piksel.\n",
        "2.   Convolution layer untuk melakukan konvolusi katriks dari piksel gambar 2D dengan filters digunakan berturut 32, 64, 128, dan 256. Kernel size yang digunakan berukuran 3x3. Activation function adalah menggunakan `relu`, dengan alasan `relu` cukup ringan secara komputasi dan cukup baik dalam mengestimasi hidden layer\n",
        "3.   MaxPooling Layer untuk melakukan max pool elemen pada matriks dari piksel gambar, yaitu mengambil max value dari tiap submatriks.\n",
        "4. Dense Layer\n",
        "5. Flatten Layer untuk melakukan reduksi dimensi dari matriks piksel gambar.\n",
        "6. Sebelumnya digunakan dropout layer untuk melakukan deaktivasi layer secara random guna menghindari overfitting, namun karena yang ingin dicapai adalah akurasi tertinggi maka layer ini dihilangkan.\n",
        "7. Output layer guna mengeluarkan hasil akhir, pada layer ini digunakan activation function yang berbeda. Dari explorasi sumber dan experimen langsung, ditemukan activation function yang baik adalah `softmax` dan `sigmoid`, namun karena `softmax` sedikit lebih baik (khusus untuk activation akhir/output dan juga bisa identifikasi kelas) maka digunakan `softmax`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIN4TTi4Ysn"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation= 'softmax'))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIxTkLrcY684"
      },
      "source": [
        "**Kedelapan**, menggunakan `model.compile()` untuk melakukan setting sebelum melakukan ftting dari model kita, disini digunakan beberapa bonus yang tidak dijelaskan secara mendalam di kelas, yaitu \n",
        "\n",
        "\n",
        "1.   Loss function, terkait dengan cost atau dengan kata lain nilai objektif dari pembelajaran algoritma CNN. Dari referensi diatas dan eksperimen diperoleh loss function yang baik dan sesuai dengan use case,\n",
        "     * `categorical_crossentropy`, secara umum digunakan untuk kategorisasi objek yang memiliki beberapa kelas klasifikasi (> 2) namun tetap lingkupnya diskrit. \n",
        "     * `SigmoidFocalCrossEntropy`, secara khusus digunakan untuk image classification\n",
        "     <p> Namun berdasarkan eksperimen, lebih tinggi akurasi dengan menggunakan `categorical_crossentropy`, maka loss function inilah yang akan lebih diprefer untuk kasus ini sekaligus digunakan sebagai example. </p>\n",
        "2.   Optimizer, guna mengpotimasi algortima, berdasar sumber diatas dan eksperimen, diperoleh alternatif optimizer function yang baik adalah\n",
        "     * `Adam` + AMSGrad (paling stabil dan rata-rata paling tinggi)\n",
        "     * `Adam` *no tuning*\n",
        "     * `SGD` + Momentum\n",
        "     * `SGD` + Momentum + Nesterov (secara rata-rata lebih jelek, namun terkadang bisa lumayan tinggi)\n",
        "     * `RMSProp`\n",
        "<p>Karena pertimbangan diatas, maka saya akan mencontohkan dengan menggunakan Adam + tuning AMSGrad.</p> \n",
        "3.   Metrics, yakni hal yang ingin menjadi pertimbangan dan ditampilkan saat proses fitting. Oleh karena yang diminta adalah accuracy, maka metric hanya diisi dengan accuracy. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJk0tuG6IH_o"
      },
      "source": [
        "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# Untuk opsi lain dari loss, uncomment salah satu dibawah ini\n",
        "\n",
        "# loss = SigmoidFocalCrossEntropy()\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "\n",
        "# Untuk opsi lain dari optimizer, uncomment salah satu dibawah ini\n",
        "\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "# opt = 'rmsprop'\n",
        "\n",
        "# opt = Adam()\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UDyUzlPgklt"
      },
      "source": [
        "**Kesembilan**, dilakukan fitting model dengan method `model.fit()`, disini juga dilakukan komputasi waktu training model dengan library bawaan `time`. Berikut ini juga dirinci beberapa konfigurasi pada fitting dan juga ada beberapa yang tidak diajarkan di kelas, \n",
        "\n",
        "\n",
        "1.   Steps atau langkah yang dilakukan tiap epoch sebanyak 25 (lihat langkah pengerjaan keenam)\n",
        "2.   Epoch untuk training data sebanyak 20\n",
        "3.   Validation step dan verbose berturut-turn 5 dan 2\n",
        "4.   Digunakan callback bawaan dari keras yang memiliki fungsi\n",
        "     * `EarlyStopping`, berfungsi untuk menghentikan lebih awal jika setelah N turn hasil yang didapatkan tidak membaik, disini disetting N = 4 dan juga mengembalikan nilai terbaik.\n",
        "     * `ReduceLROnPlateau`, berfungsi untuk mengurangi parameter *Learning Rate* dari algoritma saat berada di *Plateau* (sekitar puncak lokal) untuk menghindari penurunan akurasi secara curam, disini diatur `patience` sebesar 2.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8A30LlQIRln",
        "outputId": "10e738a1-57f8-449f-a32a-708969d4245f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from time import time\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2,\n",
        "        callbacks=[\n",
        "           EarlyStopping(patience=4, restore_best_weights=True),\n",
        "           ReduceLROnPlateau(patience=2)\n",
        "        ]\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7VS2iLog7aZ"
      },
      "source": [
        "Dari sini, didapati akurasi terbaik sebesar **99.44%** dan sebesar **99.44%** di akhir pada `val` data, sedangkan akurasi terbaik sebesar **99.44%** dan sebesar **99.44%** di akhir pada `train` data. Untuk waktu eksekusi, training dan validasi data memakan waktu selama **1411 s** ~ **24 min**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjwHrefXBbT1"
      },
      "source": [
        "**Kesepuluh**, ini opsional, semisal anda ingin mencoba memasukkan untuk menguji suatu image tangan guna diklasifikasikan ke dalam salah satu kategori (paper, rock, scissors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMbRbv-Og1q_"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as mpimg\n",
        "# %matplotlib inline\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  # imgplot = plt.imshow(img)\n",
        "  # x = image.img_to_array(img)\n",
        "  # x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  print(classes)\n",
        "\n",
        "  # if classes==0:\n",
        "  #   print('clean')\n",
        "  # else:\n",
        "  #   print('messy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ewNS6vvUAV",
        "outputId": "ef9c5572-e889-40f0-8291-fa7919aa0a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2,\n",
        "        callbacks=[\n",
        "           EarlyStopping(patience=4, restore_best_weights=True),\n",
        "           ReduceLROnPlateau(patience=2)\n",
        "        ]\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 65s - loss: 1.0936 - accuracy: 0.4040 - val_loss: 0.9730 - val_accuracy: 0.4722\n",
            "Epoch 2/20\n",
            "25/25 - 65s - loss: 1.0230 - accuracy: 0.4840 - val_loss: 0.8638 - val_accuracy: 0.6222\n",
            "Epoch 3/20\n",
            "25/25 - 65s - loss: 0.6393 - accuracy: 0.7500 - val_loss: 0.5746 - val_accuracy: 0.8222\n",
            "Epoch 4/20\n",
            "25/25 - 65s - loss: 0.4310 - accuracy: 0.8491 - val_loss: 0.3365 - val_accuracy: 0.8444\n",
            "Epoch 5/20\n",
            "25/25 - 65s - loss: 0.3156 - accuracy: 0.8826 - val_loss: 0.3109 - val_accuracy: 0.8833\n",
            "Epoch 6/20\n",
            "25/25 - 65s - loss: 0.2551 - accuracy: 0.9108 - val_loss: 0.2045 - val_accuracy: 0.9222\n",
            "Epoch 7/20\n",
            "25/25 - 68s - loss: 0.1998 - accuracy: 0.9360 - val_loss: 0.2225 - val_accuracy: 0.9500\n",
            "Epoch 8/20\n",
            "25/25 - 65s - loss: 0.1472 - accuracy: 0.9512 - val_loss: 0.1414 - val_accuracy: 0.9611\n",
            "Epoch 9/20\n",
            "25/25 - 65s - loss: 0.1470 - accuracy: 0.9497 - val_loss: 0.1385 - val_accuracy: 0.9722\n",
            "Epoch 10/20\n",
            "25/25 - 65s - loss: 0.1685 - accuracy: 0.9543 - val_loss: 0.1308 - val_accuracy: 0.9556\n",
            "Epoch 11/20\n",
            "25/25 - 65s - loss: 0.0889 - accuracy: 0.9794 - val_loss: 0.1426 - val_accuracy: 0.9556\n",
            "Epoch 12/20\n",
            "25/25 - 65s - loss: 0.0970 - accuracy: 0.9756 - val_loss: 0.0999 - val_accuracy: 0.9667\n",
            "Epoch 13/20\n",
            "25/25 - 65s - loss: 0.0699 - accuracy: 0.9809 - val_loss: 0.1031 - val_accuracy: 0.9667\n",
            "Epoch 14/20\n",
            "25/25 - 65s - loss: 0.0725 - accuracy: 0.9779 - val_loss: 0.1341 - val_accuracy: 0.9722\n",
            "Epoch 15/20\n",
            "25/25 - 65s - loss: 0.0817 - accuracy: 0.9794 - val_loss: 0.0502 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "25/25 - 68s - loss: 0.0644 - accuracy: 0.9802 - val_loss: 0.0442 - val_accuracy: 0.9944\n",
            "Epoch 17/20\n",
            "25/25 - 65s - loss: 0.0658 - accuracy: 0.9809 - val_loss: 0.0696 - val_accuracy: 0.9833\n",
            "Epoch 18/20\n",
            "25/25 - 65s - loss: 0.0547 - accuracy: 0.9855 - val_loss: 0.0532 - val_accuracy: 0.9889\n",
            "Epoch 19/20\n",
            "25/25 - 65s - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
            "Epoch 20/20\n",
            "25/25 - 66s - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.0219 - val_accuracy: 0.9944\n",
            "--- Finished in 1368.2804353237152 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Z-LOqcS8TP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ecRhUjGq53",
        "outputId": "e8498dea-e5bb-4f0b-b8a3-9abc348cd13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 61s - loss: 1.1057 - accuracy: 0.3857 - val_loss: 1.0379 - val_accuracy: 0.4778\n",
            "Epoch 2/20\n",
            "25/25 - 60s - loss: 0.9092 - accuracy: 0.5625 - val_loss: 0.4784 - val_accuracy: 0.8278\n",
            "Epoch 3/20\n",
            "25/25 - 61s - loss: 0.5933 - accuracy: 0.7470 - val_loss: 0.4154 - val_accuracy: 0.7722\n",
            "Epoch 4/20\n",
            "25/25 - 60s - loss: 0.4447 - accuracy: 0.8209 - val_loss: 0.3415 - val_accuracy: 0.8889\n",
            "Epoch 5/20\n",
            "25/25 - 60s - loss: 0.3921 - accuracy: 0.8613 - val_loss: 0.1968 - val_accuracy: 0.9611\n",
            "Epoch 6/20\n",
            "25/25 - 60s - loss: 0.3574 - accuracy: 0.8758 - val_loss: 0.1613 - val_accuracy: 0.9611\n",
            "Epoch 7/20\n",
            "25/25 - 60s - loss: 0.3267 - accuracy: 0.8941 - val_loss: 0.1358 - val_accuracy: 0.9667\n",
            "Epoch 8/20\n",
            "25/25 - 64s - loss: 0.2878 - accuracy: 0.8918 - val_loss: 0.1171 - val_accuracy: 0.9722\n",
            "Epoch 9/20\n",
            "25/25 - 60s - loss: 0.2549 - accuracy: 0.9200 - val_loss: 0.1159 - val_accuracy: 0.9611\n",
            "Epoch 10/20\n",
            "25/25 - 60s - loss: 0.1758 - accuracy: 0.9436 - val_loss: 0.2959 - val_accuracy: 0.8833\n",
            "Epoch 11/20\n",
            "25/25 - 60s - loss: 0.2391 - accuracy: 0.9093 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
            "Epoch 12/20\n",
            "25/25 - 60s - loss: 0.1554 - accuracy: 0.9466 - val_loss: 0.0578 - val_accuracy: 0.9889\n",
            "Epoch 13/20\n",
            "25/25 - 61s - loss: 0.1182 - accuracy: 0.9627 - val_loss: 0.1410 - val_accuracy: 0.9722\n",
            "Epoch 14/20\n",
            "25/25 - 60s - loss: 0.0973 - accuracy: 0.9680 - val_loss: 0.1100 - val_accuracy: 0.9722\n",
            "Epoch 15/20\n",
            "25/25 - 60s - loss: 0.1164 - accuracy: 0.9627 - val_loss: 0.1169 - val_accuracy: 0.9611\n",
            "Epoch 16/20\n",
            "25/25 - 60s - loss: 0.0776 - accuracy: 0.9764 - val_loss: 0.0581 - val_accuracy: 0.9778\n",
            "Epoch 17/20\n",
            "25/25 - 60s - loss: 0.0903 - accuracy: 0.9680 - val_loss: 0.1529 - val_accuracy: 0.9611\n",
            "Epoch 18/20\n",
            "25/25 - 63s - loss: 0.1153 - accuracy: 0.9649 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "25/25 - 60s - loss: 0.0569 - accuracy: 0.9809 - val_loss: 0.0495 - val_accuracy: 0.9944\n",
            "Epoch 20/20\n",
            "25/25 - 60s - loss: 0.0762 - accuracy: 0.9756 - val_loss: 0.0554 - val_accuracy: 0.9889\n",
            "--- Finished in 1270.845679283142 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV_Ov9VvGtVO",
        "outputId": "7796c2fd-1dfc-46c9-b3b8-a86a1f7b325c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 61s - loss: 1.0623 - accuracy: 0.4329 - val_loss: 0.8907 - val_accuracy: 0.6278\n",
            "Epoch 2/20\n",
            "25/25 - 60s - loss: 0.7797 - accuracy: 0.6540 - val_loss: 0.3596 - val_accuracy: 0.8611\n",
            "Epoch 3/20\n",
            "25/25 - 60s - loss: 0.5865 - accuracy: 0.7675 - val_loss: 0.5703 - val_accuracy: 0.8333\n",
            "Epoch 4/20\n",
            "25/25 - 60s - loss: 0.4738 - accuracy: 0.8148 - val_loss: 0.2539 - val_accuracy: 0.9389\n",
            "Epoch 5/20\n",
            "25/25 - 60s - loss: 0.3829 - accuracy: 0.8666 - val_loss: 0.2359 - val_accuracy: 0.9500\n",
            "Epoch 6/20\n",
            "25/25 - 60s - loss: 0.3124 - accuracy: 0.8956 - val_loss: 0.0932 - val_accuracy: 0.9889\n",
            "Epoch 7/20\n",
            "25/25 - 63s - loss: 0.2023 - accuracy: 0.9306 - val_loss: 0.1108 - val_accuracy: 0.9722\n",
            "Epoch 8/20\n",
            "25/25 - 60s - loss: 0.1540 - accuracy: 0.9543 - val_loss: 0.0700 - val_accuracy: 0.9667\n",
            "Epoch 9/20\n",
            "25/25 - 60s - loss: 0.1323 - accuracy: 0.9604 - val_loss: 0.1041 - val_accuracy: 0.9667\n",
            "Epoch 10/20\n",
            "25/25 - 60s - loss: 0.1338 - accuracy: 0.9573 - val_loss: 0.0460 - val_accuracy: 0.9833\n",
            "Epoch 11/20\n",
            "25/25 - 60s - loss: 0.1188 - accuracy: 0.9688 - val_loss: 0.0733 - val_accuracy: 0.9833\n",
            "Epoch 12/20\n",
            "25/25 - 60s - loss: 0.1150 - accuracy: 0.9627 - val_loss: 0.0709 - val_accuracy: 0.9778\n",
            "Epoch 13/20\n",
            "25/25 - 60s - loss: 0.1003 - accuracy: 0.9703 - val_loss: 0.0691 - val_accuracy: 0.9778\n",
            "Epoch 14/20\n",
            "25/25 - 60s - loss: 0.0842 - accuracy: 0.9748 - val_loss: 0.1053 - val_accuracy: 0.9611\n",
            "Epoch 15/20\n",
            "25/25 - 60s - loss: 0.0926 - accuracy: 0.9710 - val_loss: 0.0583 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "25/25 - 59s - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.0936 - val_accuracy: 0.9722\n",
            "Epoch 17/20\n",
            "25/25 - 62s - loss: 0.0883 - accuracy: 0.9703 - val_loss: 0.0689 - val_accuracy: 0.9833\n",
            "Epoch 18/20\n",
            "25/25 - 60s - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.0922 - val_accuracy: 0.9722\n",
            "Epoch 19/20\n",
            "25/25 - 60s - loss: 0.0975 - accuracy: 0.9695 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "25/25 - 60s - loss: 0.0660 - accuracy: 0.9840 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
            "--- Finished in 1258.7073538303375 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqKadqZaFHU"
      },
      "source": [
        "Dari sini, didapati akurasi sebesar **99.44%** pada `val` data, sedangkan akurasi sebesar **98.02%** pada `train` data sendiri. Untuk waktu eksekusi, training dan validasi data memakan waktu selama **1411 s** ~ **24 min**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efHTda8irWsm"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications import VGG16\n",
        "\n",
        "\n",
        "prior = VGG16(\n",
        "    include_top=False, \n",
        "    weights='imagenet',\n",
        "    input_shape=(150, 150, 3)\n",
        ")\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(prior)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "# model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True)\n",
        "\n",
        "model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=7,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}