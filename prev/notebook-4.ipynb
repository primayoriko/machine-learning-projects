{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaUCvrFVVxf"
      },
      "source": [
        "<p> <strong>Nama:</strong> Naufal Prima Yoriko</p>\n",
        "<p> <strong>Email:</strong> primayoriko@gmail.com </p>\n",
        "<p> <strong>Username:</strong> primayoriko </p>\n",
        "<p> <strong>Dicoding Profile:</strong> https://www.dicoding.com/users/primayoriko </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Gu5tHLWn4b"
      },
      "source": [
        "# **Submission PaperRockScissors**\n",
        "\n",
        "Sebelum menuju ke langkah pengerjaan, ini terdapat beberapa referensi yang saya pakai\n",
        "\n",
        "1.   Neural Network Activation Function in Keras\n",
        "     *   https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
        "     *   https://keras.io/api/layers/activations/\n",
        "\n",
        "2.   Loss Function in Keras\n",
        "     *   https://neptune.ai/blog/keras-loss-functions\n",
        "     *   https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "     *   https://keras.io/api/losses/\n",
        "     *   https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "\n",
        "3.   Callback in Keras\n",
        "     * https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/\n",
        "\n",
        "4.   Optimization in Keras\n",
        "     * https://keras.io/api/optimizers/ \n",
        "\n",
        "5.   Performance comparison\n",
        "     * https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/\n",
        "     * https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\n",
        "     * https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/70253\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvJ4okkL4BVz"
      },
      "source": [
        "Berikut ini adalah tahap-tahap pengerjaan yang saya lakukan dalam memeroleh hasil dari Image Processing menggunakan CNN (*Convolutional Neural Network*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynODMQpPW8tu"
      },
      "source": [
        "**Pertama**, mendownload file dari web dicoding dengan menggunakan utilitas `wget`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7gmOZAWtrTD",
        "outputId": "ba317087-d9b0-4ffb-dc69-4b56658829c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-01 22:48:04--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/zip]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M  8.25MB/s    in 45s     \n",
            "\n",
            "2020-11-01 22:48:50 (6.80 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aicDtAVnXGbI"
      },
      "source": [
        "**Kedua**, melakukan ekstraksi dari file yang didownload dengan menggunakan `zipfile`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on8Gsccut4hn"
      },
      "source": [
        "import zipfile,os\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnUXREs-XTli"
      },
      "source": [
        "**Ketiga**, dengan menggunakan library tambahan yaitu `split-folder`, saya melakukan splitting dari file-file gambar menjadi training (`train`) dan validation (`val`) data. \n",
        "\n",
        "**Note:** referensi split saya dapat dari forum dicoding, saya rasa karena dari forum, bukan website luar, tidak apa-apa untuk diikuti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HbKvdJ8xg4g",
        "outputId": "2027ed9c-3a24-4b1d-f320-6a8998c01a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', output='/tmp/rockpaperscissors/splitted', seed=1337, ratio=(.6, .4))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 2188 files [00:00, 3567.03 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVQBG8DaYGVg"
      },
      "source": [
        "**Keempat**, saya mencatat direktori dari tiap tipe data, `train` dan `val` data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYcmKDZXuBEv",
        "outputId": "970e27eb-baac-4ac3-d5c0-b1a628108b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_dir = '/tmp/rockpaperscissors/splitted'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "print(train_dir)\n",
        "print(validation_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/rockpaperscissors/splitted/train\n",
            "/tmp/rockpaperscissors/splitted/val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tHb1z0kYSAb"
      },
      "source": [
        "**Kelima**, mencatat direktori dari tiap-tiap kategori gambar dan juga mencatat total file image di tiap segmennya, untuk berjaga semisal akan dibutuhkan kedepannya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWfP7CkUuJiv",
        "outputId": "9a545a9f-9863-4ea5-b32f-39dab3abc066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_paper_dir = os.path.join(train_dir, 'paper')\n",
        "train_scissors_dir = os.path.join(train_dir, 'scissors')\n",
        "train_rock_dir = os.path.join(train_dir, 'rock')\n",
        "\n",
        "validation_paper_dir = os.path.join(validation_dir, 'paper')\n",
        "validation_scissors_dir = os.path.join(validation_dir, 'scissors')\n",
        "validation_rock_dir = os.path.join(validation_dir, 'rock')\n",
        "\n",
        "train_paper = len(os.listdir(train_paper_dir))\n",
        "train_scissors = len(os.listdir(train_scissors_dir))\n",
        "train_rock = len(os.listdir(train_rock_dir))\n",
        "\n",
        "validation_paper = len(os.listdir(validation_paper_dir))\n",
        "validation_scissors = len(os.listdir(validation_scissors_dir))\n",
        "validation_rock = len(os.listdir(validation_rock_dir))\n",
        "\n",
        "total_train = train_paper + train_scissors + train_rock\n",
        "total_validation = validation_paper + validation_scissors + validation_rock\n",
        "\n",
        "print(total_train)\n",
        "print(total_validation)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1312\n",
            "876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1DVvWsgYveG"
      },
      "source": [
        "**Keenam**, pembuatan generator image dari gambar-gambar yang tersedia, dengan menggunakan `ImageDataGenerator` dari Keras. Fungsi dari image data generator ini adalah untuk membantu mengklasifikasikan suatu gambar ke kategoti tertentu karena pada gambar mungkin ada faktor tertentu yang membedakan tampilan (diluar karena perbedaan objek), seperti jarak/ukuran, orientasi, gradasi warna, dll.\n",
        "\n",
        "Disini kode yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qJYcVJVztO1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    shear_range=0.2,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode = 'nearest'\n",
        "                  )\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    shear_range=0.2,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode = 'nearest'\n",
        "                  )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPPl7qqb9BH7"
      },
      "source": [
        "**Keenam**, Membuat pengaturan dimensi image, class, dan juga flow dari transfer data image dalam pembuatan model di tiap batchnya.\n",
        "\n",
        "Disini kode yang digunakan kurang lebih seperti yang ada di modul `Latihan Membuat Model Klasifikasi Gambar` di kelas ini. Namun, terdapat penyesuaian size tiap batch-nya sekaligus `class_mode` nya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfXlhNo3miH",
        "outputId": "0061e2d6-8c00-49fc-8665-9d2912fda0a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "# Diasumsikan akan dibuat dibuat 25 step tiap epoch\n",
        "steps_per_epoch = 25\n",
        "\n",
        "# Maka berikut ini jumlah file di tiap flow\n",
        "train_per_batch = ceil(total_train/steps_per_epoch)\n",
        "val_per_batch = ceil(total_validation/steps_per_epoch)\n",
        "print(train_per_batch)\n",
        "print(val_per_batch)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    target_size=(150, 150),\n",
        "                    batch_size=train_per_batch,\n",
        "                    class_mode='categorical'\n",
        "                  )\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                          validation_dir,\n",
        "                          target_size=(150, 150),\n",
        "                          batch_size=val_per_batch,\n",
        "                          class_mode='categorical'\n",
        "                        )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "36\n",
            "Found 1312 images belonging to 3 classes.\n",
            "Found 876 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjjqtJVEYy5J"
      },
      "source": [
        "**Ketujuh**, membuat struktur dari CNN. CNN yang dibuat disini, sesuai spesifikasi menggunakan model sequensial, yang susunannya dibebaskan (asal memiliki > 1 hidden layer).\n",
        "\n",
        "Disini kode/model yang digunakan memiliki struktur dasar dari `Latihan Membuat Model Klasifikasi Gambar` di kelas ini. Namun, metode penulisan dibuat lebih modular dan juga secara umum dapat dijelaskan bahwa struktur CNN yang sequensial memiliki 1 layer input, 9 layer hidden, dan 1 layer output.\n",
        "\n",
        "Aksi yang dilakukan antara lain dapat diringkas sebagai berikut\n",
        "\n",
        "\n",
        "1.   Convolution layerm untuk melakukan konvolusi katriks dari piksel gambar 2D dengan filters digunakan berturut 32, 64, 128, dan 256. Kernel size yang digunakan berukuran 3x3. Activation function adalah menggunakan `relu`, dengan alasan `relu` cukup ringan secara komputasi dan cukup baik dalam mengestimasi hidden layer\n",
        "2.   MaxPooling Layer untuk melakukan max pool elemen pada matriks dari piksel gambar, yaitu mengambil max value dari tiap submatriks.\n",
        "3. Dense Layer\n",
        "4. Flatten Layer untuk melakukan reduksi dimensi dari matriks piksel gambar.\n",
        "5. Sebelumnya digunakan dropout layer untuk melakukan deaktivasi layer secara random guna menghindari overfitting, namun karena yang ingin dicapai adalah akurasi tertinggi maka layer ini dihilangkan.\n",
        "6. Output layer guna mengeluarkan hasil akhir, pada layer ini digunakan activation function yang berbeda. Dari explorasi sumber dan experimen langsung, ditemukan activation function yang baik adalah `softmax` dan `sigmoid`, namun karena `softmax` sedikit lebih baik (khusus untuk activation akhir/output karena bisa identifikasi kelas) maka digunakan `softmax`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIN4TTi4Ysn"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation= 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIxTkLrcY684"
      },
      "source": [
        "**Kedelapan**, menggunakan `model.compile()` untuk melakukan setting sebelum melakukan ftting dari model kita, disini digunakan beberapa bonus yang tidak dijelaskan secara mendalam di kelas, yaitu \n",
        "\n",
        "\n",
        "1.   Loss function\n",
        "2.   Optimizer\n",
        "3.   Metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJk0tuG6IH_o"
      },
      "source": [
        "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# Untuk opsi lain dari loss, uncomment salah satu dibawah ini\n",
        "\n",
        "# loss = SigmoidFocalCrossEntropy()\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "\n",
        "# Untuk opsi lain dari optimizer, uncomment salah satu dibawah ini\n",
        "\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "# opt = 'rmsprop'\n",
        "\n",
        "# opt = Adam()\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UDyUzlPgklt"
      },
      "source": [
        "**Kesembilan**, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8A30LlQIRln"
      },
      "source": [
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2,\n",
        "        callbacks=[\n",
        "           EarlyStopping(patience=4, restore_best_weights=True),\n",
        "           ReduceLROnPlateau(patience=2)\n",
        "        ]\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7VS2iLog7aZ"
      },
      "source": [
        "Dari sini, didapati akurasi sebesar **99.44%** pada `val` data, sedangkan akurasi sebesar **98.02%** pada `train` data sendiri. Untuk waktu eksekusi, training dan validasi data memakan waktu selama **1411 s** ~ **24 min**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjwHrefXBbT1"
      },
      "source": [
        "**Kesepuluh**, ini opsional, semisal anda ingin mencoba memasukkan untuk menguji suatu image tangan guna diklasifikasikan ke dalam salah satu kategori (paper, rock, scissors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMbRbv-Og1q_"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as mpimg\n",
        "# %matplotlib inline\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  # imgplot = plt.imshow(img)\n",
        "  # x = image.img_to_array(img)\n",
        "  # x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  print(classes)\n",
        "\n",
        "  # if classes==0:\n",
        "  #   print('clean')\n",
        "  # else:\n",
        "  #   print('messy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCgLsqRGiD90",
        "outputId": "73afeb59-13e1-4148-d841-d8c9ae2bb8c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=12,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "25/25 - 60s - loss: 1.0997 - accuracy: 0.3780 - val_loss: 0.9508 - val_accuracy: 0.5778\n",
            "Epoch 2/12\n",
            "25/25 - 59s - loss: 0.8968 - accuracy: 0.6029 - val_loss: 0.5696 - val_accuracy: 0.7167\n",
            "Epoch 3/12\n",
            "25/25 - 59s - loss: 0.4877 - accuracy: 0.8064 - val_loss: 0.1893 - val_accuracy: 0.9444\n",
            "Epoch 4/12\n",
            "25/25 - 63s - loss: 0.3170 - accuracy: 0.8956 - val_loss: 0.2244 - val_accuracy: 0.9500\n",
            "Epoch 5/12\n",
            "25/25 - 59s - loss: 0.2428 - accuracy: 0.9200 - val_loss: 0.1806 - val_accuracy: 0.9278\n",
            "Epoch 6/12\n",
            "25/25 - 59s - loss: 0.1888 - accuracy: 0.9345 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
            "Epoch 7/12\n",
            "25/25 - 59s - loss: 0.1434 - accuracy: 0.9596 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
            "Epoch 8/12\n",
            "25/25 - 59s - loss: 0.1311 - accuracy: 0.9604 - val_loss: 0.2228 - val_accuracy: 0.9556\n",
            "Epoch 9/12\n",
            "25/25 - 59s - loss: 0.1186 - accuracy: 0.9642 - val_loss: 0.0234 - val_accuracy: 0.9944\n",
            "Epoch 10/12\n",
            "25/25 - 60s - loss: 0.0907 - accuracy: 0.9726 - val_loss: 0.0623 - val_accuracy: 0.9833\n",
            "Epoch 11/12\n",
            "25/25 - 59s - loss: 0.0907 - accuracy: 0.9718 - val_loss: 0.0846 - val_accuracy: 0.9833\n",
            "Epoch 12/12\n",
            "25/25 - 59s - loss: 0.1079 - accuracy: 0.9604 - val_loss: 0.0380 - val_accuracy: 0.9889\n",
            "--- Finished in 748.6572399139404 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ewNS6vvUAV",
        "outputId": "ef9c5572-e889-40f0-8291-fa7919aa0a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2,\n",
        "        callbacks=[\n",
        "           EarlyStopping(patience=4, restore_best_weights=True),\n",
        "           ReduceLROnPlateau(patience=2)\n",
        "        ]\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 65s - loss: 1.0936 - accuracy: 0.4040 - val_loss: 0.9730 - val_accuracy: 0.4722\n",
            "Epoch 2/20\n",
            "25/25 - 65s - loss: 1.0230 - accuracy: 0.4840 - val_loss: 0.8638 - val_accuracy: 0.6222\n",
            "Epoch 3/20\n",
            "25/25 - 65s - loss: 0.6393 - accuracy: 0.7500 - val_loss: 0.5746 - val_accuracy: 0.8222\n",
            "Epoch 4/20\n",
            "25/25 - 65s - loss: 0.4310 - accuracy: 0.8491 - val_loss: 0.3365 - val_accuracy: 0.8444\n",
            "Epoch 5/20\n",
            "25/25 - 65s - loss: 0.3156 - accuracy: 0.8826 - val_loss: 0.3109 - val_accuracy: 0.8833\n",
            "Epoch 6/20\n",
            "25/25 - 65s - loss: 0.2551 - accuracy: 0.9108 - val_loss: 0.2045 - val_accuracy: 0.9222\n",
            "Epoch 7/20\n",
            "25/25 - 68s - loss: 0.1998 - accuracy: 0.9360 - val_loss: 0.2225 - val_accuracy: 0.9500\n",
            "Epoch 8/20\n",
            "25/25 - 65s - loss: 0.1472 - accuracy: 0.9512 - val_loss: 0.1414 - val_accuracy: 0.9611\n",
            "Epoch 9/20\n",
            "25/25 - 65s - loss: 0.1470 - accuracy: 0.9497 - val_loss: 0.1385 - val_accuracy: 0.9722\n",
            "Epoch 10/20\n",
            "25/25 - 65s - loss: 0.1685 - accuracy: 0.9543 - val_loss: 0.1308 - val_accuracy: 0.9556\n",
            "Epoch 11/20\n",
            "25/25 - 65s - loss: 0.0889 - accuracy: 0.9794 - val_loss: 0.1426 - val_accuracy: 0.9556\n",
            "Epoch 12/20\n",
            "25/25 - 65s - loss: 0.0970 - accuracy: 0.9756 - val_loss: 0.0999 - val_accuracy: 0.9667\n",
            "Epoch 13/20\n",
            "25/25 - 65s - loss: 0.0699 - accuracy: 0.9809 - val_loss: 0.1031 - val_accuracy: 0.9667\n",
            "Epoch 14/20\n",
            "25/25 - 65s - loss: 0.0725 - accuracy: 0.9779 - val_loss: 0.1341 - val_accuracy: 0.9722\n",
            "Epoch 15/20\n",
            "25/25 - 65s - loss: 0.0817 - accuracy: 0.9794 - val_loss: 0.0502 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "25/25 - 68s - loss: 0.0644 - accuracy: 0.9802 - val_loss: 0.0442 - val_accuracy: 0.9944\n",
            "Epoch 17/20\n",
            "25/25 - 65s - loss: 0.0658 - accuracy: 0.9809 - val_loss: 0.0696 - val_accuracy: 0.9833\n",
            "Epoch 18/20\n",
            "25/25 - 65s - loss: 0.0547 - accuracy: 0.9855 - val_loss: 0.0532 - val_accuracy: 0.9889\n",
            "Epoch 19/20\n",
            "25/25 - 65s - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
            "Epoch 20/20\n",
            "25/25 - 66s - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.0219 - val_accuracy: 0.9944\n",
            "--- Finished in 1368.2804353237152 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzPbBFW8tdCl",
        "outputId": "f2f5c49b-1ec8-4456-fc1b-3652c4d697be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2,\n",
        "        callbacks=[\n",
        "           EarlyStopping(patience=4, restore_best_weights=True),\n",
        "           ReduceLROnPlateau(patience=2)\n",
        "        ]\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 66s - loss: 1.0710 - accuracy: 0.3986 - val_loss: 0.9783 - val_accuracy: 0.4611\n",
            "Epoch 2/20\n",
            "25/25 - 65s - loss: 0.7798 - accuracy: 0.6441 - val_loss: 0.6434 - val_accuracy: 0.7556\n",
            "Epoch 3/20\n",
            "25/25 - 66s - loss: 0.5252 - accuracy: 0.7866 - val_loss: 0.3868 - val_accuracy: 0.8500\n",
            "Epoch 4/20\n",
            "25/25 - 66s - loss: 0.4447 - accuracy: 0.8323 - val_loss: 0.4355 - val_accuracy: 0.8556\n",
            "Epoch 5/20\n",
            "25/25 - 66s - loss: 0.3918 - accuracy: 0.8590 - val_loss: 0.4577 - val_accuracy: 0.8167\n",
            "Epoch 6/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrC7cQvHTDBd",
        "outputId": "12f623cf-339a-4e45-f48c-6efdd364a9c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2,\n",
        "        callbacks=[\n",
        "           EarlyStopping(patience=4, restore_best_weights=True),\n",
        "           ReduceLROnPlateau(patience=2)\n",
        "        ]\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 65s - loss: 1.1106 - accuracy: 0.3392 - val_loss: 1.0968 - val_accuracy: 0.3167\n",
            "Epoch 2/20\n",
            "25/25 - 65s - loss: 1.0096 - accuracy: 0.4604 - val_loss: 0.7014 - val_accuracy: 0.6389\n",
            "Epoch 3/20\n",
            "25/25 - 65s - loss: 0.6138 - accuracy: 0.7485 - val_loss: 0.5221 - val_accuracy: 0.7611\n",
            "Epoch 4/20\n",
            "25/25 - 65s - loss: 0.4763 - accuracy: 0.8232 - val_loss: 0.3978 - val_accuracy: 0.8500\n",
            "Epoch 5/20\n",
            "25/25 - 66s - loss: 0.3869 - accuracy: 0.8567 - val_loss: 0.5060 - val_accuracy: 0.8389\n",
            "Epoch 6/20\n",
            "25/25 - 65s - loss: 0.4018 - accuracy: 0.8483 - val_loss: 0.3652 - val_accuracy: 0.8667\n",
            "Epoch 7/20\n",
            "25/25 - 65s - loss: 0.4220 - accuracy: 0.8361 - val_loss: 0.3134 - val_accuracy: 0.8833\n",
            "Epoch 8/20\n",
            "25/25 - 65s - loss: 0.3012 - accuracy: 0.8902 - val_loss: 0.3489 - val_accuracy: 0.8833\n",
            "Epoch 9/20\n",
            "25/25 - 69s - loss: 0.2487 - accuracy: 0.9108 - val_loss: 0.3162 - val_accuracy: 0.9111\n",
            "Epoch 10/20\n",
            "25/25 - 65s - loss: 0.1965 - accuracy: 0.9314 - val_loss: 0.1742 - val_accuracy: 0.9389\n",
            "Epoch 11/20\n",
            "25/25 - 65s - loss: 0.1906 - accuracy: 0.9383 - val_loss: 0.2215 - val_accuracy: 0.9278\n",
            "Epoch 12/20\n",
            "25/25 - 65s - loss: 0.1701 - accuracy: 0.9428 - val_loss: 0.1580 - val_accuracy: 0.9556\n",
            "Epoch 13/20\n",
            "25/25 - 65s - loss: 0.1446 - accuracy: 0.9535 - val_loss: 0.2347 - val_accuracy: 0.9500\n",
            "Epoch 14/20\n",
            "25/25 - 65s - loss: 0.1415 - accuracy: 0.9527 - val_loss: 0.1383 - val_accuracy: 0.9389\n",
            "Epoch 15/20\n",
            "25/25 - 65s - loss: 0.1358 - accuracy: 0.9558 - val_loss: 0.1450 - val_accuracy: 0.9556\n",
            "Epoch 16/20\n",
            "25/25 - 65s - loss: 0.1373 - accuracy: 0.9566 - val_loss: 0.2257 - val_accuracy: 0.9167\n",
            "Epoch 17/20\n",
            "25/25 - 65s - loss: 0.1052 - accuracy: 0.9634 - val_loss: 0.1417 - val_accuracy: 0.9611\n",
            "Epoch 18/20\n",
            "25/25 - 68s - loss: 0.1072 - accuracy: 0.9596 - val_loss: 0.1860 - val_accuracy: 0.9333\n",
            "--- Finished in 1231.2608618736267 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Z-LOqcS8TP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ecRhUjGq53",
        "outputId": "e8498dea-e5bb-4f0b-b8a3-9abc348cd13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from time import time\n",
        "\n",
        "start_time = time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 61s - loss: 1.1057 - accuracy: 0.3857 - val_loss: 1.0379 - val_accuracy: 0.4778\n",
            "Epoch 2/20\n",
            "25/25 - 60s - loss: 0.9092 - accuracy: 0.5625 - val_loss: 0.4784 - val_accuracy: 0.8278\n",
            "Epoch 3/20\n",
            "25/25 - 61s - loss: 0.5933 - accuracy: 0.7470 - val_loss: 0.4154 - val_accuracy: 0.7722\n",
            "Epoch 4/20\n",
            "25/25 - 60s - loss: 0.4447 - accuracy: 0.8209 - val_loss: 0.3415 - val_accuracy: 0.8889\n",
            "Epoch 5/20\n",
            "25/25 - 60s - loss: 0.3921 - accuracy: 0.8613 - val_loss: 0.1968 - val_accuracy: 0.9611\n",
            "Epoch 6/20\n",
            "25/25 - 60s - loss: 0.3574 - accuracy: 0.8758 - val_loss: 0.1613 - val_accuracy: 0.9611\n",
            "Epoch 7/20\n",
            "25/25 - 60s - loss: 0.3267 - accuracy: 0.8941 - val_loss: 0.1358 - val_accuracy: 0.9667\n",
            "Epoch 8/20\n",
            "25/25 - 64s - loss: 0.2878 - accuracy: 0.8918 - val_loss: 0.1171 - val_accuracy: 0.9722\n",
            "Epoch 9/20\n",
            "25/25 - 60s - loss: 0.2549 - accuracy: 0.9200 - val_loss: 0.1159 - val_accuracy: 0.9611\n",
            "Epoch 10/20\n",
            "25/25 - 60s - loss: 0.1758 - accuracy: 0.9436 - val_loss: 0.2959 - val_accuracy: 0.8833\n",
            "Epoch 11/20\n",
            "25/25 - 60s - loss: 0.2391 - accuracy: 0.9093 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
            "Epoch 12/20\n",
            "25/25 - 60s - loss: 0.1554 - accuracy: 0.9466 - val_loss: 0.0578 - val_accuracy: 0.9889\n",
            "Epoch 13/20\n",
            "25/25 - 61s - loss: 0.1182 - accuracy: 0.9627 - val_loss: 0.1410 - val_accuracy: 0.9722\n",
            "Epoch 14/20\n",
            "25/25 - 60s - loss: 0.0973 - accuracy: 0.9680 - val_loss: 0.1100 - val_accuracy: 0.9722\n",
            "Epoch 15/20\n",
            "25/25 - 60s - loss: 0.1164 - accuracy: 0.9627 - val_loss: 0.1169 - val_accuracy: 0.9611\n",
            "Epoch 16/20\n",
            "25/25 - 60s - loss: 0.0776 - accuracy: 0.9764 - val_loss: 0.0581 - val_accuracy: 0.9778\n",
            "Epoch 17/20\n",
            "25/25 - 60s - loss: 0.0903 - accuracy: 0.9680 - val_loss: 0.1529 - val_accuracy: 0.9611\n",
            "Epoch 18/20\n",
            "25/25 - 63s - loss: 0.1153 - accuracy: 0.9649 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "25/25 - 60s - loss: 0.0569 - accuracy: 0.9809 - val_loss: 0.0495 - val_accuracy: 0.9944\n",
            "Epoch 20/20\n",
            "25/25 - 60s - loss: 0.0762 - accuracy: 0.9756 - val_loss: 0.0554 - val_accuracy: 0.9889\n",
            "--- Finished in 1270.845679283142 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV_Ov9VvGtVO",
        "outputId": "7796c2fd-1dfc-46c9-b3b8-a86a1f7b325c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3), activation= 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True, lr=0.001)\n",
        "# opt = SGD(\n",
        "#     lr=0.01, momentum=0.9, nesterov=False\n",
        "# )\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 61s - loss: 1.0623 - accuracy: 0.4329 - val_loss: 0.8907 - val_accuracy: 0.6278\n",
            "Epoch 2/20\n",
            "25/25 - 60s - loss: 0.7797 - accuracy: 0.6540 - val_loss: 0.3596 - val_accuracy: 0.8611\n",
            "Epoch 3/20\n",
            "25/25 - 60s - loss: 0.5865 - accuracy: 0.7675 - val_loss: 0.5703 - val_accuracy: 0.8333\n",
            "Epoch 4/20\n",
            "25/25 - 60s - loss: 0.4738 - accuracy: 0.8148 - val_loss: 0.2539 - val_accuracy: 0.9389\n",
            "Epoch 5/20\n",
            "25/25 - 60s - loss: 0.3829 - accuracy: 0.8666 - val_loss: 0.2359 - val_accuracy: 0.9500\n",
            "Epoch 6/20\n",
            "25/25 - 60s - loss: 0.3124 - accuracy: 0.8956 - val_loss: 0.0932 - val_accuracy: 0.9889\n",
            "Epoch 7/20\n",
            "25/25 - 63s - loss: 0.2023 - accuracy: 0.9306 - val_loss: 0.1108 - val_accuracy: 0.9722\n",
            "Epoch 8/20\n",
            "25/25 - 60s - loss: 0.1540 - accuracy: 0.9543 - val_loss: 0.0700 - val_accuracy: 0.9667\n",
            "Epoch 9/20\n",
            "25/25 - 60s - loss: 0.1323 - accuracy: 0.9604 - val_loss: 0.1041 - val_accuracy: 0.9667\n",
            "Epoch 10/20\n",
            "25/25 - 60s - loss: 0.1338 - accuracy: 0.9573 - val_loss: 0.0460 - val_accuracy: 0.9833\n",
            "Epoch 11/20\n",
            "25/25 - 60s - loss: 0.1188 - accuracy: 0.9688 - val_loss: 0.0733 - val_accuracy: 0.9833\n",
            "Epoch 12/20\n",
            "25/25 - 60s - loss: 0.1150 - accuracy: 0.9627 - val_loss: 0.0709 - val_accuracy: 0.9778\n",
            "Epoch 13/20\n",
            "25/25 - 60s - loss: 0.1003 - accuracy: 0.9703 - val_loss: 0.0691 - val_accuracy: 0.9778\n",
            "Epoch 14/20\n",
            "25/25 - 60s - loss: 0.0842 - accuracy: 0.9748 - val_loss: 0.1053 - val_accuracy: 0.9611\n",
            "Epoch 15/20\n",
            "25/25 - 60s - loss: 0.0926 - accuracy: 0.9710 - val_loss: 0.0583 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "25/25 - 59s - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.0936 - val_accuracy: 0.9722\n",
            "Epoch 17/20\n",
            "25/25 - 62s - loss: 0.0883 - accuracy: 0.9703 - val_loss: 0.0689 - val_accuracy: 0.9833\n",
            "Epoch 18/20\n",
            "25/25 - 60s - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.0922 - val_accuracy: 0.9722\n",
            "Epoch 19/20\n",
            "25/25 - 60s - loss: 0.0975 - accuracy: 0.9695 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "25/25 - 60s - loss: 0.0660 - accuracy: 0.9840 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
            "--- Finished in 1258.7073538303375 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqKadqZaFHU"
      },
      "source": [
        "Dari sini, didapati akurasi sebesar **99.44%** pada `val` data, sedangkan akurasi sebesar **98.02%** pada `train` data sendiri. Untuk waktu eksekusi, training dan validasi data memakan waktu selama **1411 s** ~ **24 min**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efHTda8irWsm"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications import VGG16\n",
        "\n",
        "\n",
        "prior = VGG16(\n",
        "    include_top=False, \n",
        "    weights='imagenet',\n",
        "    input_shape=(150, 150, 3)\n",
        ")\n",
        "\n",
        "model = Sequential(name=\"simple_sequential\")\n",
        "model.add(prior)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(3, activation= 'sigmoid'))\n",
        "# model.add(Dense(3, activation= 'softmax'))\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "opt = Adam(amsgrad=True)\n",
        "\n",
        "model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
        "              optimizer = opt,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time.time()\n",
        "schema = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=25,\n",
        "        epochs=7,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=5,\n",
        "        verbose=2\n",
        "      )\n",
        "print(\"--- Finished in %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}